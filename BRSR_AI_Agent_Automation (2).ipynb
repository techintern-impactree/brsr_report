{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kGKOQWqpXNv",
        "outputId": "fc61997e-4276-451b-9763-0f45f3179485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IOrXXWLXTB-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d0c2f7-5df1-4e63-ef86-e7297c1369cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# INSTALL DEPENDENCIES\n",
        "# ---------------------------\n",
        "!pip install -q pdfplumber python-docx requests bitsandbytes transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlwzqYopTx9H"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# IMPORTS\n",
        "# ---------------------------\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import pdfplumber\n",
        "import requests\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqaX3ph2YNfv",
        "outputId": "ca14fa39-fd5d-47a0-8c87-e18edeb513ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Loading JSON template: brsr_questions.json\n",
            "[*] Reading Annual Report PDF: BFUTILITIE_27112025155734_BRSR_BFUL_27112025.pdf\n",
            "[*] Llama 3 is processing Section General: SECTION A: GENERAL DISCLOSURES...\n",
            "[*] Llama 3 is processing Section General: SECTION B: MANAGEMENT AND PROCESS DISCLOSURES...\n",
            "[*] Llama 3 is processing Section General: SECTION C: PRINCIPLE WISE PERFORMANCE DISCLOSURE...\n",
            "[*] Saving populated report to: BRSR_Populated_Llama3.json\n",
            "[+] SUCCESS: Process complete.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import pdfplumber\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Replace this with your actual public Ngrok URL (e.g., \"https://abcd-1234.ngrok-free.app\")\n",
        "NGROK_BASE_URL = \"https://buddy-scorpionic-hilda.ngrok-free.dev/\"\n",
        "MODEL_NAME = \"llama3\"\n",
        "\n",
        "class BRSRJsonEngine:\n",
        "    \"\"\"\n",
        "    Advanced Engine to process structured BRSR JSON templates using Llama 3 via Ngrok.\n",
        "    Extracts data from PDFs and populates the JSON schema.\n",
        "    \"\"\"\n",
        "    def __init__(self, pdf_path: str, json_path: str, ngrok_url: str):\n",
        "        self.pdf_path = pdf_path\n",
        "        self.json_path = json_path\n",
        "        self.ngrok_url = ngrok_url.rstrip('/')\n",
        "        self.report_json = {}\n",
        "        self.context_text = \"\"\n",
        "        self.final_output = {}\n",
        "\n",
        "    def _query_llama(self, prompt: str) -> Any:\n",
        "        \"\"\"Calls Llama 3 via Ngrok endpoint with JSON formatting enabled and robust error handling.\"\"\"\n",
        "        url = f\"{self.ngrok_url}/api/chat\"\n",
        "\n",
        "        system_instruction = (\n",
        "            \"You are a professional BRSR Auditor. You will be given a portion of a JSON template \"\n",
        "            \"and text from an Annual Report. Your task is to fill the 'answer' or 'tableData' fields \"\n",
        "            \"based on the report. Maintain absolute numeric precision. If info is missing, use 'Not Disclosed'. \"\n",
        "            \"Return ONLY a valid JSON object.\"\n",
        "        )\n",
        "\n",
        "        payload = {\n",
        "            \"model\": MODEL_NAME,\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": system_instruction},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            \"stream\": False,\n",
        "            \"format\": \"json\"\n",
        "        }\n",
        "\n",
        "        for i in range(5):\n",
        "            try:\n",
        "                response = requests.post(url, json=payload, timeout=300)\n",
        "                response.raise_for_status()\n",
        "                result = response.json()\n",
        "\n",
        "                # Defensive Extraction\n",
        "                if not isinstance(result, dict):\n",
        "                    continue\n",
        "\n",
        "                message = result.get('message', {})\n",
        "                if isinstance(message, dict):\n",
        "                    text_response = message.get('content', '')\n",
        "                else:\n",
        "                    text_response = str(message)\n",
        "\n",
        "                if not text_response:\n",
        "                    continue\n",
        "\n",
        "                # Clean Llama output: Locate actual JSON block\n",
        "                text_clean = text_response.strip()\n",
        "                start_idx = text_clean.find('{')\n",
        "                end_idx = text_clean.rfind('}') + 1\n",
        "\n",
        "                if start_idx != -1 and end_idx > start_idx:\n",
        "                    json_str = text_clean[start_idx:end_idx]\n",
        "                    return json.loads(json_str)\n",
        "                else:\n",
        "                    return json.loads(text_clean)\n",
        "\n",
        "            except Exception as e:\n",
        "                if i < 4:\n",
        "                    time.sleep(2**i)\n",
        "                else:\n",
        "                    print(f\"[!] Llama 3 API Final Error: {e}\")\n",
        "                    return None\n",
        "        return None\n",
        "\n",
        "    def load_files(self):\n",
        "        \"\"\"Loads the JSON template and PDF content.\"\"\"\n",
        "        if not os.path.exists(self.json_path):\n",
        "            print(f\"[-] Error: JSON path {self.json_path} not found.\")\n",
        "            return False\n",
        "\n",
        "        print(f\"[*] Loading JSON template: {self.json_path}\")\n",
        "        with open(self.json_path, 'r') as f:\n",
        "            try:\n",
        "                self.report_json = json.load(f)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"[-] Error: Failed to parse JSON template: {e}\")\n",
        "                return False\n",
        "\n",
        "        print(f\"[*] Reading Annual Report PDF: {self.pdf_path}\")\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with pdfplumber.open(self.pdf_path) as pdf:\n",
        "                # Processing 80 pages to stay within local LLM context limits\n",
        "                for page in pdf.pages[:80]:\n",
        "                    extracted = page.extract_text()\n",
        "                    if extracted: text += extracted + \"\\n\"\n",
        "            self.context_text = text\n",
        "            return len(text) > 0\n",
        "        except Exception as e:\n",
        "            print(f\"[-] PDF Error: {e}\")\n",
        "            return False\n",
        "\n",
        "    def process_sections(self):\n",
        "        \"\"\"Iterates through the JSON sections and populates data using Llama 3.\"\"\"\n",
        "        # Create a deep copy to preserve the original structure\n",
        "        self.final_output = json.loads(json.dumps(self.report_json))\n",
        "\n",
        "        sections_list = []\n",
        "\n",
        "        # Robust discovery of the sections list\n",
        "        if isinstance(self.final_output, list):\n",
        "            sections_list = self.final_output\n",
        "        elif isinstance(self.final_output, dict):\n",
        "            # Check 'sections' key first\n",
        "            potential_sections = self.final_output.get(\"sections\")\n",
        "            if isinstance(potential_sections, list):\n",
        "                sections_list = potential_sections\n",
        "            elif isinstance(potential_sections, dict):\n",
        "                # If 'sections' is a dict of ID -> Section, extract values\n",
        "                sections_list = list(potential_sections.values())\n",
        "            # If no 'sections' key, check if root itself is a section\n",
        "            elif any(k in self.final_output for k in [\"subsections\", \"fields\", \"principles\", \"content\"]):\n",
        "                sections_list = [self.final_output]\n",
        "            else:\n",
        "                # Fallback: Find any nested value that looks like a section\n",
        "                for val in self.final_output.values():\n",
        "                    if isinstance(val, list) and len(val) > 0 and isinstance(val[0], dict):\n",
        "                        if any(k in val[0] for k in [\"subsections\", \"fields\", \"question\"]):\n",
        "                            sections_list = val\n",
        "                            break\n",
        "\n",
        "                if not sections_list:\n",
        "                    print(\"[-] Error: Could not locate a list of sections in the JSON.\")\n",
        "                    print(f\"[*] Root keys found: {list(self.final_output.keys())}\")\n",
        "                    return\n",
        "        else:\n",
        "            print(\"[-] Error: JSON template structure is invalid.\")\n",
        "            return\n",
        "\n",
        "        for section in sections_list:\n",
        "            if not isinstance(section, dict):\n",
        "                continue\n",
        "\n",
        "            # Identification logic\n",
        "            section_id = section.get(\"sectionId\", section.get(\"id\", \"General\"))\n",
        "            section_title = section.get(\"sectionTitle\", section.get(\"title\", \"Untitled Section\"))\n",
        "            print(f\"[*] Llama 3 is processing Section {section_id}: {section_title}...\")\n",
        "\n",
        "            # Context window management: ~30k chars is safer for Llama 3 8B\n",
        "            prompt = f\"\"\"\n",
        "            ANNUAL REPORT CONTEXT (EXCERPT):\n",
        "            {self.context_text[:30000]}\n",
        "\n",
        "            TASK:\n",
        "            Below is a JSON schema for a BRSR reporting section.\n",
        "            Please provide values for all 'fields' and 'tables' defined in this snippet using data from the report.\n",
        "\n",
        "            JSON SCHEMA TO FILL:\n",
        "            {json.dumps(section, indent=2)}\n",
        "\n",
        "            RETURN:\n",
        "            Return the SAME JSON structure, but for every object in 'fields', update the 'answer' key.\n",
        "            For every object in 'tables', update the 'dataRows' or relevant value keys based on report evidence.\n",
        "            \"\"\"\n",
        "\n",
        "            filled_section = self._query_llama(prompt)\n",
        "            if filled_section and isinstance(filled_section, dict):\n",
        "                # Merge AI results back into the template section\n",
        "                section.update(filled_section)\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "    def save_result(self, output_path: str):\n",
        "        \"\"\"Saves the fully populated JSON.\"\"\"\n",
        "        print(f\"[*] Saving populated report to: {output_path}\")\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(self.final_output, f, indent=4)\n",
        "        print(\"[+] SUCCESS: Process complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Settings\n",
        "    INPUT_JSON = \"brsr_questions.json\"\n",
        "    INPUT_PDF = \"BFUTILITIE_27112025155734_BRSR_BFUL_27112025.pdf\"\n",
        "    OUTPUT_FILE = \"BRSR_Populated_Llama3.json\"\n",
        "\n",
        "    # Verify Ngrok URL is set\n",
        "    if \"YOUR_NGROK_URL\" in NGROK_BASE_URL:\n",
        "        print(\"[!] Warning: Please update NGROK_BASE_URL with your public tunnel address.\")\n",
        "    else:\n",
        "        # Initialize and Run\n",
        "        engine = BRSRJsonEngine(pdf_path=INPUT_PDF, json_path=INPUT_JSON, ngrok_url=NGROK_BASE_URL)\n",
        "\n",
        "        try:\n",
        "            if engine.load_files():\n",
        "                engine.process_sections()\n",
        "                engine.save_result(OUTPUT_FILE)\n",
        "            else:\n",
        "                print(\"[-] Error: Failed to initialize source files.\")\n",
        "        except Exception as e:\n",
        "            print(f\"[-] Pipeline Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxVDeBUOYRbn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}